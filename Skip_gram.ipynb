{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skip_gram.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B63NMsRG9N75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "glov_dir='/content/sample_data/text8.zip'\n",
        "import zipfile\n",
        "with zipfile.ZipFile(glov_dir,\"r\") as zip_ref:\n",
        "    zip_ref.extractall('/content/sample_data/reception_gloe')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpU9k-olzPQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def preprocess(text):\n",
        "\n",
        "    # Replace punctuation with tokens so we can use them in our model\n",
        "    text = text.lower()\n",
        "    text = text.replace('.', ' <PERIOD> ')\n",
        "    text = text.replace(',', ' <COMMA> ')\n",
        "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
        "    text = text.replace(';', ' <SEMICOLON> ')\n",
        "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
        "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    text = text.replace('(', ' <LEFT_PAREN> ')\n",
        "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
        "    text = text.replace('--', ' <HYPHENS> ')\n",
        "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    # text = text.replace('\\n', ' <NEW_LINE> ')\n",
        "    text = text.replace(':', ' <COLON> ')\n",
        "    words = text.split()\n",
        "    \n",
        "    # Remove all words with  5 or fewer occurences\n",
        "    word_counts = Counter(words)\n",
        "    trimmed_words = [word for word in words if word_counts[word] > 5]\n",
        "\n",
        "    return trimmed_words\n",
        "\n",
        "\n",
        "def create_lookup_tables(words):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param words: Input list of words\n",
        "    :return: Two dictionaries, vocab_to_int, int_to_vocab\n",
        "    \"\"\"\n",
        "    word_counts = Counter(words)\n",
        "    # sorting the words from most to least frequent in text occurrence\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    # create int_to_vocab dictionaries\n",
        "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "\n",
        "    return vocab_to_int, int_to_vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud8-myMBwdVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os_dir='/content/sample_data/reception_gloe/text8'\n",
        "with open(os_dir) as f:\n",
        "  data=f.read()\n",
        "text_processed=preprocess(data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YA8kKd72aGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0547419e-37b9-43a4-f57b-bb72bbe91f0c"
      },
      "source": [
        "text_processed[:10]\n",
        "print(len(text_processed))\n",
        "print(len(set(text_processed)))\n",
        "vocab_to_int, int_to_vocab= create_lookup_tables(text_processed)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16680599\n",
            "63641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxlo8xMR3Z2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "48290b7f-f796-4deb-aa08-d0da7ece121a"
      },
      "source": [
        "int_words=[vocab_to_int[word] for word in text_processed]\n",
        "int_words[:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5233,\n",
              " 3080,\n",
              " 11,\n",
              " 5,\n",
              " 194,\n",
              " 1,\n",
              " 3133,\n",
              " 45,\n",
              " 58,\n",
              " 155,\n",
              " 127,\n",
              " 741,\n",
              " 476,\n",
              " 10571,\n",
              " 133,\n",
              " 0,\n",
              " 27349,\n",
              " 1,\n",
              " 0,\n",
              " 102,\n",
              " 854,\n",
              " 2,\n",
              " 0,\n",
              " 15067,\n",
              " 58112,\n",
              " 1,\n",
              " 0,\n",
              " 150,\n",
              " 854,\n",
              " 3580]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUFXBPliEMmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "0f8f8fd6-b8de-4c12-ec3a-acfe090e5d67"
      },
      "source": [
        "from collections import Counter\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "threshold=1e-5\n",
        "word_count=Counter(int_words)\n",
        "freqs={word:count/len(int_words) for word,count in word_count.items()}\n",
        "drop_proba={word:1-np.sqrt(threshold/freqs[word]) for word,_ in word_count.items()}\n",
        "train_words=[word for word in int_words if random.random() < (1 - drop_proba[word])]\n",
        "print(train_words[:30])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5233, 3080, 3133, 741, 10571, 27349, 2, 15067, 58112, 854, 10712, 371, 539, 2757, 7088, 1052, 44611, 2877, 5233, 1134, 2621, 25, 8983, 279, 4147, 59, 6437, 4186, 153, 5233]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryPLWw08HxvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_target(words, idx, window_size=5):\n",
        "   R = np.random.randint(1, window_size+1)\n",
        "   print(R)\n",
        "   start=idx-R if (idx-R) >0 else 0\n",
        "   stop=idx+R\n",
        "   target_words=words[start:idx] + words[idx+1:stop+1]\n",
        "   return list(target_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvbuccYsJh0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(words, batch_size, window_size=5):\n",
        "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
        "    \n",
        "    n_batches = len(words)//batch_size\n",
        "    \n",
        "    # only full batches\n",
        "    words = words[:n_batches*batch_size]\n",
        "    \n",
        "    for idx in range(0, len(words), batch_size):\n",
        "        x, y = [], []\n",
        "        batch = words[idx:idx+batch_size]\n",
        "        for ii in range(len(batch)):\n",
        "            batch_x = batch[ii]\n",
        "            batch_y = get_target(batch, ii, window_size)\n",
        "            y.extend(batch_y)\n",
        "            x.extend([batch_x]*len(batch_y))\n",
        "        yield x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED1iWvIpOK6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f9e6b26a-b28a-4427-81c5-dfd468f1a6b0"
      },
      "source": [
        "int_text = [i for i in range(20)]\n",
        "x,y = next(get_batches(int_text, batch_size=4, window_size=5))\n",
        "print(x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "1\n",
            "4\n",
            "1\n",
            "[0, 0, 0, 1, 1, 2, 2, 2, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jExjrKeYQLZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc07263b-a802-4005-8584-1c7e7f63ec38"
      },
      "source": [
        "import torch\n",
        "tt=[[1,2,3]]\n",
        "l=torch.LongTensor(tt)\n",
        "print(l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDUYWFwPOORQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(embedding,valid_size=16,valid_windows=100,device='cpu'):\n",
        "  embed_vectors=embedding.weight\n",
        "\n",
        "  magnitude_vector=embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
        "\n",
        "  valid_examples=np.array(random.sample(range(valid_windows),valid_size//2))\n",
        "  valid_examples=np.append(valid_examples, random.sample(range(1000,1000+valid_windows),valid_size//2))\n",
        "  valid_examples=torch.LongTensor(valid_examples).to(device)\n",
        "  valid_vectors=embedding(valid_examples)\n",
        "  similarities=torch.mm(valid_vectors,embed_vectors.t())/magnitude_vector\n",
        "  return valid_examples,similarities\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0azmWo315mBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9wk15_E54cw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SkipGram(nn.Module):\n",
        "  def __init__(self,n_vocab,n_embeddings):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embed=nn.Embedding(n_vocab,n_embeddings)\n",
        "    self.output=nn.Linear(n_embeddings,n_vocab)\n",
        "    self.log=nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.embed(x)\n",
        "    outputed=self.output(x)\n",
        "    log_scores=self.log(outputed)\n",
        "\n",
        "    return log_scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhHUUqjC63sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training loop\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "embedding_dim=300 # you can change, if you want\n",
        "\n",
        "model = SkipGram(len(vocab_to_int), embedding_dim).to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "print_every = 500\n",
        "steps = 0\n",
        "epochs = 5\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "  for inputs ,targets in get_batches(train_words,512):\n",
        "    steps+=1\n",
        "    inputs,targets=torch.LongTensor(inputs), torch.LongTensor(targets)\n",
        "    inputs, targets=inputs.to(device), targets.to(device)\n",
        "    log_ps=model(inputs)\n",
        "    loss=criterion(log_ps,targets)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if steps % print_every ==0:\n",
        "      valid_examples, valid_similarities= cosine_similarity(model.embed,device=device)\n",
        "      _,close_ids=valid_similarities.topk(6)\n",
        "      valid_examples, close_ids = valid_examples.to('cpu'), close_ids.to('cpu')\n",
        "      for ii, valid_idx in enumerate(valid_examples):\n",
        "        closest=[int_to_vocab[idex.item()] for idex in close_ids[ii]][1:]\n",
        "        print(int_to_vocab[valid_idx.item()] + \" | \" + ', '.join(closest))\n",
        "        print(\"...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTnvW4pAcYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # getting examples and similarities      \n",
        "  # getting examples and similarities      \n",
        "  valid_examples, valid_similarities = cosine_similarity(model.embed, device=device)\n",
        "  _, closest_idxs = valid_similarities.topk(6) # topk highest similarities\n",
        "  valid_examples, closest_idxs = valid_examples.to('cpu'), closest_idxs.to('cpu')\n",
        "  for ii, valid_idx in enumerate(valid_examples):\n",
        "      closest_words = [int_to_vocab[idx.item()] for idx in closest_idxs[ii]][1:]\n",
        "      print(int_to_vocab[valid_idx.item()] + \" | \" + ', '.join(closest_words))\n",
        "  print(\"...\")\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}